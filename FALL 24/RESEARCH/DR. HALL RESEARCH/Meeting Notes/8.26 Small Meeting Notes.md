## 8.26 Small Group Meeting -- Notes

### Work I've Done
#### Toy Model
- Edited toy model somewhat to work with DSHARP dataset.
- Kinda scrappy because the original toy model had me define number of clusters myself, which I didn't change when I tweaked it here, but it's something I am aware of.
- Don't know what specific parameters data was clustered by.
- Used edge detection for centered cropping.
- Used Euclidean Distance, Ward's Linkage, Agglomerative Clustering

#### Sapelo2
- Got training 4-5PM today, should get access very soon.
- Will be able to start producing high-particle simulations & avoid MCFOST issues I've had in the past.

#### Goldwater
- I'm applying! Any advice would be appreciated (I have already grilled Lainey).

#### Next Steps
- [ ] Consider more refined clustering method:
    - Q: How can I identify what the algorithm is clustering by?
    - Q: Code was only clustering based on image data (HOG)--what other data from .FITS files can I use for more insightful clustering?
    - Rewrite code to eliminate user-defined number of clusters.
    - Clean up code & consider creating a library for this .FITS analysis (I know astropy exists).
    - Consider other clustering/unsupervised methods (k-means alone, hybrid k-means and agglomerative, Constrastive Learning, **suggestions**).
 
- [ ] Produce high-particle disc simulations on Sapelo2 to combine with small DSHARP Dataset; cluster small-but-less-small dataset.
    - Q: How do I simulate ALMA noise? CASA? Simple image editing Python script? 
    - I'm hoping this will serve as a 'base case' for a much larger dataset.
    - Compare with Contrastive Learning results.

- [ ] Work with big dataset and lots of simulations.
    - Compare with contrastive learning results?
